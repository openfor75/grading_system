import streamlit as st
import pandas as pd
import os
import smtplib
import time
import io
import traceback
import threading
import uuid
import re
import sqlite3
import json
import random
from email.mime.text import MIMEText           # â† ä¿®æ­£é€™è¡Œ
from email.mime.multipart import MIMEMultipart # â† ä¿®æ­£é€™è¡Œ
from datetime import datetime, date, timedelta
import pytz
import gspread
from oauth2client.service_account import ServiceAccountCredentials
from googleapiclient.discovery import build
from googleapiclient.http import MediaIoBaseUpload

# --- 1. ç¶²é è¨­å®š ---
st.set_page_config(page_title="è¡›ç”Ÿç³¾å¯Ÿè©•åˆ†ç³»çµ±(é›²ç«¯æ——è‰¦ç‰ˆ)", layout="wide", page_icon="ğŸ§¹")

# --- 2. æ•æ‰å…¨åŸŸéŒ¯èª¤ ---
try:
    # ==========================================
    # 0. åŸºç¤è¨­å®šèˆ‡æ™‚å€
    # ==========================================
    TW_TZ = pytz.timezone('Asia/Taipei')

    MAX_IMAGE_BYTES = 10 * 1024 * 1024  # å–®æª”åœ–ç‰‡ 10MB ä¸Šé™
    QUEUE_DB_PATH = "task_queue.db"     # SQLite ä½‡åˆ—æª”æ¡ˆ
    
    # Google Sheet ç¶²å€
    SHEET_URL = "https://docs.google.com/spreadsheets/d/1nrX4v-K0xr-lygiBXrBwp4eWiNi9LY0-LIr-K1vBHDw/edit#gid=0"

    SHEET_TABS = {
        "main": "main_data", 
        "settings": "settings",
        "roster": "roster",
        "inspectors": "inspectors",
        "duty": "duty",
        "teachers": "teachers",
        "appeals": "appeals"
    }

    EXPECTED_COLUMNS = [
        "æ—¥æœŸ", "é€±æ¬¡", "ç­ç´š", "è©•åˆ†é …ç›®", "æª¢æŸ¥äººå“¡",
        "å…§æƒåŸå§‹åˆ†", "å¤–æƒåŸå§‹åˆ†", "åƒåœ¾åŸå§‹åˆ†", "åƒåœ¾å…§æƒåŸå§‹åˆ†", "åƒåœ¾å¤–æƒåŸå§‹åˆ†", "æ™¨é–“æ‰“æƒåŸå§‹åˆ†", "æ‰‹æ©Ÿäººæ•¸",
        "å‚™è¨»", "é•è¦ç´°é …", "ç…§ç‰‡è·¯å¾‘", "ç™»éŒ„æ™‚é–“", "ä¿®æ­£", "æ™¨æƒæœªåˆ°è€…", "ç´€éŒ„ID"
    ]

    APPEAL_COLUMNS = [
        "ç”³è¨´æ—¥æœŸ", "ç­ç´š", "é•è¦æ—¥æœŸ", "é•è¦é …ç›®", "åŸå§‹æ‰£åˆ†", "ç”³è¨´ç†ç”±", "ä½è­‰ç…§ç‰‡", "è™•ç†ç‹€æ…‹", "ç™»éŒ„æ™‚é–“", "å°æ‡‰ç´€éŒ„ID"
    ]

    # ==========================================
    # 1. Google é€£ç·šæ•´åˆ
    # ==========================================

    @st.cache_resource
    def get_credentials():
        scope = ['https://spreadsheets.google.com/feeds', 'https://www.googleapis.com/auth/drive']
        if "gcp_service_account" not in st.secrets:
            st.error("âŒ æ‰¾ä¸åˆ° secrets è¨­å®š")
            return None
        creds_dict = dict(st.secrets["gcp_service_account"])
        return ServiceAccountCredentials.from_json_keyfile_dict(creds_dict, scope)

    @st.cache_resource
    def get_gspread_client():
        try:
            creds = get_credentials()
            if not creds: return None
            return gspread.authorize(creds)
        except Exception as e:
            st.error(f"âŒ Google Sheet é€£ç·šå¤±æ•—: {e}"); return None

    @st.cache_resource
    def get_drive_service():
        try:
            creds = get_credentials()
            if not creds: return None
            return build('drive', 'v3', credentials=creds, cache_discovery=False)
        except Exception as e:
            st.warning(f"âš ï¸ Google Drive é€£ç·šå¤±æ•—: {e}"); return None

    @st.cache_resource(ttl=21600)
    def get_spreadsheet_object():
        client = get_gspread_client()
        if not client: return None
        try: return client.open_by_url(SHEET_URL)
        except Exception as e: st.error(f"âŒ ç„¡æ³•é–‹å•Ÿè©¦ç®—è¡¨: {e}"); return None

    def get_worksheet(tab_name):
        max_retries = 3; wait_time = 2
        sheet = get_spreadsheet_object()
        if not sheet: return None
        for attempt in range(max_retries):
            try:
                try: return sheet.worksheet(tab_name)
                except gspread.WorksheetNotFound:
                    cols = 20 if tab_name != "appeals" else 15
                    ws = sheet.add_worksheet(title=tab_name, rows=100, cols=cols)
                    if tab_name == "appeals": ws.append_row(APPEAL_COLUMNS)
                    return ws
            except Exception as e:
                if "429" in str(e): time.sleep(wait_time * (attempt + 1)); continue
                else: print(f"âŒ è®€å–åˆ†é  '{tab_name}' å¤±æ•—: {e}"); return None
        return None

    def upload_image_to_drive(file_obj, filename):
        service = get_drive_service()
        if not service: return None
        
        folder_id = st.secrets["system_config"].get("drive_folder_id")
        if not folder_id:
            print("âš ï¸ Secrets ä¸­æœªè¨­å®š drive_folder_id")
            return None

        try:
            file_metadata = {'name': filename, 'parents': [folder_id]}
            media = MediaIoBaseUpload(file_obj, mimetype='image/jpeg')
            file = service.files().create(
                body=file_metadata, media_body=media, fields='id', supportsAllDrives=True
            ).execute()
            
            try:
                service.permissions().create(fileId=file.get('id'), body={'role': 'reader', 'type': 'anyone'}).execute()
            except: pass 
            return f"https://drive.google.com/thumbnail?id={file.get('id')}&sz=w1000"
        except Exception as e:
            print(f"âš ï¸ Drive ä¸Šå‚³å¤±æ•—: {str(e)}"); return None

    def clean_id(val):
        try:
            if pd.isna(val) or val == "": return ""
            return str(int(float(val))).strip()
        except: return str(val).strip()

    # ==========================================
    # åœ–ç‰‡æš«å­˜è³‡æ–™å¤¾ï¼šåªåœ¨æœ¬æ©ŸçŸ­æš«å­˜æ”¾ï¼Œé¿å…è¨˜æ†¶é«”çˆ†æ‰
    # ==========================================
    IMG_DIR = "evidence_photos"
    os.makedirs(IMG_DIR, exist_ok=True)

    # ==========================================
    # SQLite èƒŒæ™¯ä½‡åˆ—ç³»çµ± (Durable Queue)
    # ==========================================
    _queue_lock = threading.Lock()

    @st.cache_resource
    def get_queue_connection():
        """å–å¾— SQLite é€£ç·šä¸¦åˆå§‹åŒ– task_queue è³‡æ–™è¡¨ã€‚"""
        conn = sqlite3.connect(QUEUE_DB_PATH, check_same_thread=False)
        conn.execute("""
            CREATE TABLE IF NOT EXISTS task_queue (
                id TEXT PRIMARY KEY,
                task_type TEXT NOT NULL,
                created_ts TEXT NOT NULL,
                payload_json TEXT NOT NULL,
                status TEXT NOT NULL,          -- PENDING / IN_PROGRESS / RETRY / DONE / FAILED
                attempts INTEGER NOT NULL DEFAULT 0,
                last_error TEXT
            )
        """)
        conn.commit()
        return conn

    def enqueue_task(task_type: str, payload: dict) -> str:
        """å°‡ä»»å‹™å¯«å…¥ SQLite ä½‡åˆ—ï¼ˆæŒä¹…åŒ–ï¼‰ã€‚"""
        conn = get_queue_connection()
        task_id = str(uuid.uuid4())
        created_ts = datetime.utcnow().isoformat() + "Z"
        payload_json = json.dumps(payload, ensure_ascii=False)

        with _queue_lock:
            conn.execute(
                "INSERT INTO task_queue (id, task_type, created_ts, payload_json, status, attempts, last_error) "
                "VALUES (?, ?, ?, ?, 'PENDING', 0, NULL)",
                (task_id, task_type, created_ts, payload_json)
            )
            conn.commit()
        return task_id

    def fetch_next_task(max_attempts: int = 6):
        """å¾ä½‡åˆ—ä¸­æŠ“å‡ºä¸‹ä¸€ç­†è¦è™•ç†çš„ä»»å‹™ï¼ˆPENDING / RETRYï¼Œä¸”é‡è©¦æ¬¡æ•¸æœªè¶…éä¸Šé™ï¼‰ã€‚"""
        conn = get_queue_connection()
        with _queue_lock:
            cur = conn.cursor()
            cur.execute(
                """
                SELECT id, task_type, created_ts, payload_json, status, attempts, last_error
                FROM task_queue
                WHERE status IN ('PENDING', 'RETRY')
                  AND attempts < ?
                ORDER BY created_ts ASC
                LIMIT 1
                """,
                (max_attempts,)
            )
            row = cur.fetchone()
        if not row:
            return None

        task_id, task_type, created_ts, payload_json, status, attempts, last_error = row
        try:
            payload = json.loads(payload_json)
        except Exception:
            payload = {}
        return {
            "id": task_id,
            "task_type": task_type,
            "created_ts": created_ts,
            "payload": payload,
            "status": status,
            "attempts": attempts,
            "last_error": last_error,
        }

    def update_task_status(task_id: str, status: str, attempts: int, last_error: str | None):
        """æ›´æ–°ä»»å‹™ç‹€æ…‹ï¼é‡è©¦æ¬¡æ•¸ï¼éŒ¯èª¤è¨Šæ¯ã€‚"""
        conn = get_queue_connection()
        with _queue_lock:
            conn.execute(
                "UPDATE task_queue SET status = ?, attempts = ?, last_error = ? WHERE id = ?",
                (status, attempts, last_error, task_id),
            )
            conn.commit()

    def get_queue_pending_count() -> int:
        """å›å‚³ç›®å‰å°šæœªè™•ç†å®Œçš„ä»»å‹™æ•¸ï¼ˆPENDING / RETRY / IN_PROGRESSï¼‰ã€‚"""
        conn = get_queue_connection()
        with _queue_lock:
            cur = conn.cursor()
            cur.execute(
                "SELECT COUNT(*) FROM task_queue WHERE status IN ('PENDING', 'RETRY', 'IN_PROGRESS')"
            )
            row = cur.fetchone()
        return row[0] if row else 0

    def _exp_backoff_seconds(attempts: int) -> float:
        """æŒ‡æ•¸é€€é¿æ™‚é–“ï¼ˆç§’ï¼‰ï¼Œé¿å…ç˜‹ç‹‚é‡è©¦æ‰“çˆ† Google APIã€‚"""
        base = 1.0
        cap = 32.0
        # ç¬¬ä¸€æ¬¡å¤±æ•—å¤§ç´„ 1~2 ç§’ï¼Œä¹‹å¾Œ 2^n æ”¾å¤§ï¼Œä¸Šé™ 32 ç§’
        return random.uniform(0, min(cap, base * (2 ** max(0, attempts))))

    def _append_main_entry_row(entry: dict):
        """å¯¦éš›åŸ·è¡Œ main_data å¯«å…¥ï¼ˆåŸæœ¬ background_worker è£¡çš„é‚£æ®µå¯«å…¥é‚è¼¯ï¼‰ã€‚"""
        ws = get_worksheet(SHEET_TABS["main"])
        if not ws:
            raise RuntimeError("ç„¡æ³•å–å¾— main_data å·¥ä½œè¡¨")

        all_vals = ws.get_all_values()
        if not all_vals:
            ws.append_row(EXPECTED_COLUMNS)

        row = []
        for col in EXPECTED_COLUMNS:
            val = entry.get(col, "")
            if isinstance(val, bool):
                val = str(val).upper()
            if col == "æ—¥æœŸ":
                val = str(val)
            row.append(val)
        ws.append_row(row)

    def _append_appeal_row(entry: dict):
        """å¯¦éš›åŸ·è¡Œ appeals å¯«å…¥ã€‚"""
        ws = get_worksheet(SHEET_TABS["appeals"])
        if not ws:
            raise RuntimeError("ç„¡æ³•å–å¾— appeals å·¥ä½œè¡¨")

        all_vals = ws.get_all_values()
        if not all_vals:
            ws.append_row(APPEAL_COLUMNS)

        row = [str(entry.get(col, "")) for col in APPEAL_COLUMNS]
        ws.append_row(row)

    def process_task(task: dict, max_attempts: int = 6) -> tuple[bool, str | None]:
        """
        æ ¹æ“š task_type åŸ·è¡Œå¯¦éš›è™•ç†ï¼š
        - main_entry: ä¸Šå‚³ç…§ç‰‡åˆ° Drive â†’ å¯«å…¥ main_data
        - appeal_entry: ä¸Šå‚³ç”³è¨´ä½è­‰ â†’ å¯«å…¥ appeals
        å›å‚³ (æˆåŠŸèˆ‡å¦, éŒ¯èª¤è¨Šæ¯)
        """
        task_type = task["task_type"]
        payload = task["payload"]
        entry = payload.get("entry", {}) or {}

        try:
            if task_type == "main_entry":
                image_paths = payload.get("image_paths", []) or []
                filenames = payload.get("filenames", []) or []
                drive_links = []

                # ä¸Šå‚³è­‰æ“šç…§ç‰‡
                for path, fname in zip(image_paths, filenames):
                    if not path or not os.path.exists(path):
                        drive_links.append("UPLOAD_FAILED")
                        continue
                    with open(path, "rb") as f:
                        link = upload_image_to_drive(f, fname)
                    drive_links.append(link if link else "UPLOAD_FAILED")

                if drive_links:
                    entry["ç…§ç‰‡è·¯å¾‘"] = ";".join(drive_links)

                _append_main_entry_row(entry)
                return True, None

            elif task_type == "appeal_entry":
                image_info = payload.get("image_file")  # {"path": ..., "filename": ...}
                if image_info and image_info.get("path") and os.path.exists(image_info["path"]):
                    with open(image_info["path"], "rb") as f:
                        link = upload_image_to_drive(f, image_info["filename"])
                    entry["ä½è­‰ç…§ç‰‡"] = link if link else "UPLOAD_FAILED"
                else:
                    # æ²’æœ‰ç…§ç‰‡å°±ç•™ç©º
                    entry["ä½è­‰ç…§ç‰‡"] = entry.get("ä½è­‰ç…§ç‰‡", "")

                _append_appeal_row(entry)
                return True, None

            else:
                # æœªçŸ¥ä»»å‹™ç¨®é¡ï¼Œç›´æ¥æ¨™è¨˜ç‚ºå¤±æ•—
                return True, None

        except Exception as e:
            return False, str(e)

    def background_worker(stop_event: threading.Event | None = None):
        """èƒŒæ™¯ workerï¼šå¾ SQLite ä½‡åˆ—æŠ“ä»»å‹™ï¼Œè² è²¬é‡è©¦ã€é€€é¿èˆ‡æ¸…ç†æš«å­˜æª”ã€‚"""
        max_attempts = 6
        print("ğŸš€ èƒŒæ™¯å·¥ä½œè€…å·²å•Ÿå‹•...(SQLite Queue)")
        while True:
            if stop_event is not None and stop_event.is_set():
                break

            task = fetch_next_task(max_attempts=max_attempts)
            if not task:
                time.sleep(1.0)
                continue

            task_id = task["id"]
            attempts = int(task["attempts"] or 0)
            payload = task["payload"]

            # æ¨™è¨˜ç‚º IN_PROGRESS
            update_task_status(task_id, "IN_PROGRESS", attempts + 1, None)

            ok = False
            err_msg = None
            try:
                ok, err_msg = process_task(task, max_attempts=max_attempts)
            except Exception as e:
                err_msg = f"UNHANDLED: {e}\n{traceback.format_exc()}"
                ok = False

            # æ¸…ç†æš«å­˜æª”ï¼ˆä¸ç®¡æˆåŠŸæˆ–å¤±æ•—éƒ½åšï¼‰
            try:
                image_paths = []
                if isinstance(payload, dict):
                    if "image_paths" in payload and isinstance(payload["image_paths"], list):
                        image_paths.extend(payload["image_paths"])
                    if "image_file" in payload and isinstance(payload["image_file"], dict):
                        p = payload["image_file"].get("path")
                        if p:
                            image_paths.append(p)
                for p in image_paths:
                    if p and os.path.exists(p):
                        os.remove(p)
            except Exception as cleanup_e:
                print(f"âš ï¸ åˆªé™¤æš«å­˜æª”å¤±æ•—: {cleanup_e}")

            # æ ¹æ“šçµæœæ›´æ–°ä»»å‹™ç‹€æ…‹
            if ok:
                update_task_status(task_id, "DONE", attempts + 1, None)
                # å¯«æˆåŠŸå¾Œæ¸…å¿«å–ï¼Œè®“å‰å°æŸ¥è©¢åˆ°æœ€æ–°è³‡æ–™
                try:
                    st.cache_data.clear()
                except Exception:
                    pass
                print(f"âœ… Task {task_id}({task['task_type']}) å®Œæˆ")
            else:
                if attempts + 1 >= max_attempts:
                    update_task_status(task_id, "FAILED", attempts + 1, err_msg or "unknown error")
                    print(f"âŒ Task {task_id} æ°¸ä¹…å¤±æ•—: {err_msg}")
                else:
                    update_task_status(task_id, "RETRY", attempts + 1, err_msg or "unknown error")
                    sleep_sec = _exp_backoff_seconds(attempts)
                    print(f"âš ï¸ Task {task_id} å¤±æ•— (ç¬¬ {attempts+1} æ¬¡)ï¼Œ{sleep_sec:.1f} ç§’å¾Œé‡è©¦ã€‚éŒ¯èª¤: {err_msg}")
                    time.sleep(sleep_sec)

    @st.cache_resource
    def start_background_worker():
        stop_event = threading.Event()
        t = threading.Thread(target=background_worker, args=(stop_event,), daemon=True)
        t.start()
        return stop_event

    # å•Ÿå‹•èƒŒæ™¯ worker
    _worker_stop_event = start_background_worker()

    # ==========================================
    # 2. è³‡æ–™è®€å¯«é‚è¼¯
    # ==========================================

    @st.cache_data(ttl=60)
    def load_main_data():
        ws = get_worksheet(SHEET_TABS["main"])
        if not ws: return pd.DataFrame(columns=EXPECTED_COLUMNS)
        try:
            data = ws.get_all_records()
            df = pd.DataFrame(data)
            if df.empty: return pd.DataFrame(columns=EXPECTED_COLUMNS)
            for col in EXPECTED_COLUMNS:
                if col not in df.columns: df[col] = "" 
            
            if "ç´€éŒ„ID" not in df.columns: df["ç´€éŒ„ID"] = df.index.astype(str)
            else: df["ç´€éŒ„ID"] = df["ç´€éŒ„ID"].astype(str)

            if "ç…§ç‰‡è·¯å¾‘" in df.columns: df["ç…§ç‰‡è·¯å¾‘"] = df["ç…§ç‰‡è·¯å¾‘"].fillna("").astype(str)
            
            numeric_cols = ["å…§æƒåŸå§‹åˆ†", "å¤–æƒåŸå§‹åˆ†", "åƒåœ¾åŸå§‹åˆ†", "æ™¨é–“æ‰“æƒåŸå§‹åˆ†", "æ‰‹æ©Ÿäººæ•¸"]
            for col in numeric_cols:
                if col in df.columns: df[col] = pd.to_numeric(df[col], errors='coerce').fillna(0).astype(int)
            if "é€±æ¬¡" in df.columns: df["é€±æ¬¡"] = pd.to_numeric(df["é€±æ¬¡"], errors='coerce').fillna(0).astype(int)
            return df[EXPECTED_COLUMNS]
        except Exception as e:
            st.error(f"è®€å–è³‡æ–™éŒ¯èª¤: {e}"); return pd.DataFrame(columns=EXPECTED_COLUMNS)

        def save_entry(new_entry, uploaded_files=None):
            """
            æ¥å—å‰ç«¯é€é€²ä¾†çš„è©•åˆ†ç´€éŒ„ï¼š
            - ä¸Šå‚³çš„åœ–ç‰‡å…ˆå¯«åˆ°æœ¬æ©Ÿæš«å­˜è³‡æ–™å¤¾ IMG_DIR
            - ä½‡åˆ—è£¡åªæ”¾ã€Œæª”æ¡ˆè·¯å¾‘ + æª”åã€èˆ‡ entryï¼Œé¿å…è¨˜æ†¶é«”å£“åŠ›
            - èƒŒæ™¯ worker å†è² è²¬ä¸Šå‚³åˆ° Google Drive + å¯«å…¥è©¦ç®—è¡¨ (main_data)
            """
            image_paths = []
            file_names = []

            if uploaded_files:
                for i, up_file in enumerate(uploaded_files):
                    if not up_file:
                        continue
                    try:
                        up_file.seek(0)
                        data = up_file.read()
                    except Exception as e:
                        print(f"âš ï¸ è®€å–ä¸Šå‚³æª”å¤±æ•—: {e}")
                        continue

                    if not data:
                        continue

                    # æª”æ¡ˆå¤§å°é™åˆ¶ 10MB
                    size = len(data)
                    if size > MAX_IMAGE_BYTES:
                        mb = size / (1024 * 1024)
                        st.warning(f"ğŸ“¸ æª”æ¡ˆã€Œ{up_file.name}ã€éå¤§ ({mb:.1f} MB)ï¼Œå·²ç•¥éã€‚å–®æª”ä¸Šé™ç‚º 10 MBã€‚")
                        continue

                    logical_fname = f"{new_entry['æ—¥æœŸ']}_{new_entry['ç­ç´š']}_{i}.jpg"
                    tmp_fname = f"{datetime.now(TW_TZ).strftime('%Y%m%d%H%M%S')}_{uuid.uuid4().hex[:6]}_{logical_fname}"
                    local_path = os.path.join(IMG_DIR, tmp_fname)

                    try:
                        with open(local_path, "wb") as f:
                            f.write(data)
                        image_paths.append(local_path)
                        file_names.append(logical_fname)
                    except Exception as e:
                        print(f"âš ï¸ å¯«å…¥æš«å­˜æª”å¤±æ•—: {e}")
                        # é€™å¼µå¤±æ•—å°±ç•¥éï¼Œä¸ä¸­æ–·å…¶å®ƒæª”æ¡ˆ

            # ç¢ºä¿æ¯ç­†ç´€éŒ„éƒ½æœ‰å”¯ä¸€ç´€éŒ„IDï¼ˆæ–¹ä¾¿å¾Œå°èˆ‡ç”³è¨´å°æ‡‰ï¼‰
            if "ç´€éŒ„ID" not in new_entry or not new_entry["ç´€éŒ„ID"]:
                unique_suffix = uuid.uuid4().hex[:6]
                timestamp = datetime.now(TW_TZ).strftime("%Y%m%d%H%M%S")
                new_entry["ç´€éŒ„ID"] = f"{timestamp}_{unique_suffix}"

            payload = {
                "entry": new_entry,
                "image_paths": image_paths,
                "filenames": file_names,
            }
            task_id = enqueue_task("main_entry", payload)
            try:
                st.cache_data.clear()
            except Exception:
                pass
            print(f"ğŸ“¥ main_entry æ’å…¥ä½‡åˆ— (Task ID: {task_id})")

        def save_appeal(entry, proof_file=None):
            """
            ç”³è¨´è³‡æ–™å¯«å…¥æµç¨‹ï¼š
            - å‰ç«¯åªåšï¼šæª¢æŸ¥æ¬„ä½ + æª”æ¡ˆå¤§å° + å¯«æš«å­˜æª” + ä¸Ÿåˆ° SQLite queue
            - èƒŒæ™¯ workerï¼šä¸Šå‚³ä½è­‰ç…§ç‰‡åˆ° Drive + å¯«å…¥ appeals åˆ†é 
            """
            image_info = None  # {"path": ..., "filename": ...}

            if proof_file:
                try:
                    proof_file.seek(0)
                    data = proof_file.read()
                except Exception as e:
                    st.error(f"âŒ è®€å–ä½è­‰ç…§ç‰‡å¤±æ•—: {e}")
                    return False

                if not data:
                    st.error("âŒ ä½è­‰ç…§ç‰‡ç‚ºç©ºæª”æ¡ˆ")
                    return False

                size = len(data)
                if size > MAX_IMAGE_BYTES:
                    mb = size / (1024 * 1024)
                    st.error(f"âŒ ä½è­‰ç…§ç‰‡éå¤§ ({mb:.1f} MB)ï¼Œè«‹å£“ç¸®åˆ° 10 MB ä»¥ä¸‹å†ä¸Šå‚³ã€‚(ç›®å‰ {mb:.1f} MB)")
                    return False

                logical_fname = f"Appeal_{entry.get('ç­ç´š', '')}_{datetime.now(TW_TZ).strftime('%H%M%S')}.jpg"
                tmp_fname = f"{datetime.now(TW_TZ).strftime('%Y%m%d%H%M%S')}_{uuid.uuid4().hex[:6]}_{logical_fname}"
                local_path = os.path.join(IMG_DIR, tmp_fname)
                try:
                    with open(local_path, "wb") as f:
                        f.write(data)
                    image_info = {"path": local_path, "filename": logical_fname}
                except Exception as e:
                    st.error(f"âŒ å¯«å…¥ä½è­‰æš«å­˜æª”å¤±æ•—: {e}")
                    return False

        # é è¨­æ¬„ä½è£œé½Š
        if "ç”³è¨´æ—¥æœŸ" not in entry or not entry["ç”³è¨´æ—¥æœŸ"]:
            entry["ç”³è¨´æ—¥æœŸ"] = datetime.now(TW_TZ).strftime("%Y-%m-%d")
        entry["è™•ç†ç‹€æ…‹"] = entry.get("è™•ç†ç‹€æ…‹", "å¾…è™•ç†")
        if "ç™»éŒ„æ™‚é–“" not in entry or not entry["ç™»éŒ„æ™‚é–“"]:
            entry["ç™»éŒ„æ™‚é–“"] = datetime.now(TW_TZ).strftime("%Y-%m-%d %H:%M:%S")
        if "ç”³è¨´ID" not in entry or not entry["ç”³è¨´ID"]:
            entry["ç”³è¨´ID"] = datetime.now(TW_TZ).strftime("%Y%m%d%H%M%S") + "_" + uuid.uuid4().hex[:4]
        if "ä½è­‰ç…§ç‰‡" not in entry:
            entry["ä½è­‰ç…§ç‰‡"] = ""
    
        payload = {
            "entry": entry,
            "image_file": image_info,  # å¯èƒ½ç‚º None
        }
        task_id = enqueue_task("appeal_entry", payload)
        try:
            st.cache_data.clear()
        except Exception:
            pass
        st.success("ğŸ“© ç”³è¨´å·²æ’å…¥èƒŒæ™¯è™•ç†")
        print(f"ğŸ“¥ appeal_entry æ’å…¥ä½‡åˆ— (Task ID: {task_id})")
        return True

    @st.cache_data(ttl=60)
    def load_appeals():
        ws = get_worksheet(SHEET_TABS["appeals"])
        if not ws:
            return pd.DataFrame(columns=APPEAL_COLUMNS)

        try:
            records = ws.get_all_records()  # ä»¥ç¬¬ä¸€åˆ—ç‚ºæ¬„ä½åç¨±
            df = pd.DataFrame(records)
        except Exception:
            return pd.DataFrame(columns=APPEAL_COLUMNS)

        # ç¢ºä¿æ‰€æœ‰å®šç¾©å¥½çš„æ¬„ä½éƒ½å­˜åœ¨
        for col in APPEAL_COLUMNS:
            if col not in df.columns:
                # å°ã€Œè™•ç†ç‹€æ…‹ã€çµ¦åˆç†é è¨­ï¼Œå…¶é¤˜çµ¦ç©ºå­—ä¸²
                if col == "è™•ç†ç‹€æ…‹":
                    df[col] = "å¾…è™•ç†"
                else:
                    df[col] = ""

        # æ¬„ä½é †åºæ•´ç†æˆ APPEAL_COLUMNS
        df = df[APPEAL_COLUMNS]

        return df
    def delete_rows_by_ids(record_ids_to_delete):
        ws = get_worksheet(SHEET_TABS["main"])
        if not ws: return False
        try:
            records = ws.get_all_records()
            rows_to_delete = []
            for i, record in enumerate(records):
                if str(record.get("ç´€éŒ„ID")) in record_ids_to_delete:
                    rows_to_delete.append(i + 2)
            
            rows_to_delete.sort(reverse=True)
            for row_idx in rows_to_delete:
                ws.delete_rows(row_idx)
                time.sleep(0.8)
                
            st.cache_data.clear()
            return True
        except Exception as e:
            st.error(f"åˆªé™¤å¤±æ•—: {e}"); return False

    def update_appeal_status(appeal_row_idx, status, record_id):
        ws_appeals = get_worksheet(SHEET_TABS["appeals"])
        ws_main = get_worksheet(SHEET_TABS["main"])
        try:
            appeals_data = ws_appeals.get_all_records()
            target_row = None
            for i, row in enumerate(appeals_data):
                if str(row.get("å°æ‡‰ç´€éŒ„ID")) == str(record_id) and str(row.get("è™•ç†ç‹€æ…‹")) == "å¾…è™•ç†":
                    target_row = i + 2 
                    break
            if target_row:
                col_idx = APPEAL_COLUMNS.index("è™•ç†ç‹€æ…‹") + 1
                ws_appeals.update_cell(target_row, col_idx, status)
                if status == "å·²æ ¸å¯" and record_id:
                    main_data = ws_main.get_all_records()
                    main_target_row = None
                    for j, m_row in enumerate(main_data):
                        if str(m_row.get("ç´€éŒ„ID")) == str(record_id):
                            main_target_row = j + 2
                            break
                    if main_target_row:
                        fix_col_idx = EXPECTED_COLUMNS.index("ä¿®æ­£") + 1
                        ws_main.update_cell(main_target_row, fix_col_idx, "TRUE")
                st.cache_data.clear()
                return True, "æ›´æ–°æˆåŠŸ"
            else: return False, "æ‰¾ä¸åˆ°å°æ‡‰çš„ç”³è¨´åˆ—"
        except Exception as e: return False, str(e)

    @st.cache_data(ttl=21600)
    def load_roster_dict():
        ws = get_worksheet(SHEET_TABS["roster"])
        roster_dict = {}
        if ws:
            try:
                df = pd.DataFrame(ws.get_all_records())
                id_col = next((c for c in df.columns if "å­¸è™Ÿ" in c), None)
                class_col = next((c for c in df.columns if "ç­ç´š" in c), None)
                if id_col and class_col:
                    for _, row in df.iterrows():
                        sid = clean_id(row[id_col])
                        if sid: roster_dict[sid] = str(row[class_col]).strip()
            except: pass
        return roster_dict
        
    @st.cache_data(ttl=3600)
    def load_sorted_classes():
        ws = get_worksheet(SHEET_TABS["roster"])
        if not ws: return [], []
        try:
            df = pd.DataFrame(ws.get_all_records())
            class_col = next((c for c in df.columns if "ç­ç´š" in c), None)
            if not class_col: return [], []
            unique_classes = df[class_col].dropna().unique().tolist()
            unique_classes = [c.strip() for c in unique_classes if c.strip()]
            
            def sort_key(name):
                match = re.search(r'\d+', name)
                grade = int(match.group()) if match else 99
                return (grade, name)
            
            sorted_all = sorted(unique_classes, key=sort_key)
            structured = []
            for c in sorted_all:
                match = re.search(r'\d+', c)
                g_num = match.group() if match else "?"
                g_label = f"{g_num}å¹´ç´š" if g_num != "?" else "å…¶ä»–"
                structured.append({"grade": g_label, "name": c})
            return sorted_all, structured
        except: return [], []

    @st.cache_data(ttl=21600)
    def load_teacher_emails():
        ws = get_worksheet(SHEET_TABS["teachers"])
        email_dict = {}
        if ws:
            try:
                df = pd.DataFrame(ws.get_all_records())
                class_col = next((c for c in df.columns if "ç­ç´š" in c), None)
                mail_col = next((c for c in df.columns if "Email" in c or "ä¿¡ç®±" in c or "éƒµä»¶" in c), None)
                name_col = next((c for c in df.columns if "å°å¸«" in c or "å§“å" in c), None)
                if class_col and mail_col:
                    for _, row in df.iterrows():
                        cls = str(row[class_col]).strip()
                        mail = str(row[mail_col]).strip()
                        name = str(row[name_col]).strip() if name_col else "è€å¸«"
                        if cls and mail and "@" in mail:
                            email_dict[cls] = {"email": mail, "name": name}
            except: pass
        return email_dict

    @st.cache_data(ttl=21600)
    def load_inspector_list():
        ws = get_worksheet(SHEET_TABS["inspectors"])
        default = [{"label": "æ¸¬è©¦äººå“¡", "allowed_roles": ["å…§æƒæª¢æŸ¥"], "assigned_classes": [], "id_prefix": "æ¸¬"}]
        if not ws: return default
        try:
            df = pd.DataFrame(ws.get_all_records())
            if df.empty: return default
            inspectors = []
            id_col = next((c for c in df.columns if "å­¸è™Ÿ" in c or "ç·¨è™Ÿ" in c), None)
            role_col = next((c for c in df.columns if "è² è²¬" in c or "é …ç›®" in c), None)
            scope_col = next((c for c in df.columns if "ç­ç´š" in c or "ç¯„åœ" in c), None)
            if id_col:
                for _, row in df.iterrows():
                    s_id = clean_id(row[id_col])
                    s_role = str(row[role_col]).strip() if role_col else ""
                    allowed = []
                    if "çµ„é•·" in s_role: allowed = ["å…§æƒæª¢æŸ¥", "å¤–æƒæª¢æŸ¥", "åƒåœ¾/å›æ”¶æª¢æŸ¥", "æ™¨é–“æ‰“æƒ"]
                    elif "æ©Ÿå‹•" in s_role: allowed = ["å…§æƒæª¢æŸ¥", "å¤–æƒæª¢æŸ¥", "åƒåœ¾/å›æ”¶æª¢æŸ¥"]
                    else:
                        if "å¤–æƒ" in s_role: allowed.append("å¤–æƒæª¢æŸ¥")
                        if "åƒåœ¾" in s_role: allowed.append("åƒåœ¾/å›æ”¶æª¢æŸ¥")
                        if "æ™¨" in s_role: allowed.append("æ™¨é–“æ‰“æƒ")
                        if "å…§æƒ" in s_role: allowed.append("å…§æƒæª¢æŸ¥")
                    if not allowed: allowed = ["å…§æƒæª¢æŸ¥"]
                    s_classes = []
                    if scope_col and str(row[scope_col]):
                        raw = str(row[scope_col])
                        s_classes = [c.strip() for c in raw.replace("ã€", ";").replace(",", ";").split(";") if c.strip()]
                    prefix = s_id[0] if len(s_id) > 0 else "X"
                    inspectors.append({"label": f"å­¸è™Ÿ: {s_id}", "allowed_roles": allowed, "assigned_classes": s_classes, "id_prefix": prefix})
            return inspectors if inspectors else default
        except: return default

    @st.cache_data(ttl=60)
    def get_daily_duty(target_date):
        ws = get_worksheet(SHEET_TABS["duty"])
        if not ws: return [], "error"
        try:
            df = pd.DataFrame(ws.get_all_records())
            if df.empty: return [], "no_data"
            date_col = next((c for c in df.columns if "æ—¥æœŸ" in c), None)
            id_col = next((c for c in df.columns if "å­¸è™Ÿ" in c), None)
            loc_col = next((c for c in df.columns if "åœ°é»" in c), None)
            if date_col and id_col:
                df[date_col] = pd.to_datetime(df[date_col], errors='coerce').dt.date
                t_date = target_date if isinstance(target_date, date) else target_date.date()
                today_df = df[df[date_col] == t_date]
                res = []
                for _, row in today_df.iterrows():
                    res.append({"å­¸è™Ÿ": clean_id(row[id_col]), "æƒåœ°å€åŸŸ": str(row[loc_col]).strip() if loc_col else "", "å·²å®Œæˆæ‰“æƒ": False})
                return res, "success"
            return [], "missing_cols"
        except: return [], "error"

    @st.cache_data(ttl=21600)
    def load_settings():
        ws = get_worksheet(SHEET_TABS["settings"])
        config = {"semester_start": "2025-08-25"}
        if ws:
            try:
                data = ws.get_all_values()
                for row in data:
                    if len(row)>=2 and row[0] == "semester_start": config["semester_start"] = row[1]
            except: pass
        return config

    def save_setting(key, val):
        ws = get_worksheet(SHEET_TABS["settings"])
        if ws:
            try:
                cell = ws.find(key)
                if cell: ws.update_cell(cell.row, cell.col+1, val)
                else: ws.append_row([key, val])
                st.cache_data.clear()
                return True
            except: return False
        return False

    def send_bulk_emails(email_list):
        sender_email = st.secrets["system_config"]["smtp_email"]
        sender_password = st.secrets["system_config"]["smtp_password"]
        if not sender_email or not sender_password: return 0, "Secrets æœªè¨­å®š Email"

        sent_count = 0
        try:
            server = smtplib.SMTP('smtp.gmail.com', 587)
            server.starttls()
            server.login(sender_email, sender_password)
            for item in email_list:
                try:
                    msg = MIMEMultipart()
                    msg['From'] = sender_email
                    msg['To'] = item['email']
                    msg['Subject'] = item['subject']
                    msg.attach(MIMEText(item['body'], 'plain'))
                    server.sendmail(sender_email, item['email'], msg.as_string())
                    sent_count += 1
                except Exception as inner_e:
                    print(f"å€‹åˆ¥å¯„é€å¤±æ•—: {inner_e}")
            server.quit()
            return sent_count, "ç™¼é€ä½œæ¥­çµæŸ"
        except Exception as e:
            return sent_count, str(e)

    def check_duplicate_record(df, check_date, inspector, role, target_class=None):
        if df.empty: return False
        try:
            df["æ—¥æœŸStr"] = df["æ—¥æœŸ"].astype(str)
            check_date_str = str(check_date)
            mask = (df["æ—¥æœŸStr"] == check_date_str) & (df["æª¢æŸ¥äººå“¡"] == inspector) & (df["è©•åˆ†é …ç›®"] == role)
            if target_class: mask = mask & (df["ç­ç´š"] == target_class)
            return not df[mask].empty
        except: return False

    # ==========================================
    # 3. ä¸»ç¨‹å¼ä»‹é¢
    # ==========================================
    SYSTEM_CONFIG = load_settings()
    ROSTER_DICT = load_roster_dict()
    INSPECTOR_LIST = load_inspector_list()
    TEACHER_MAILS = load_teacher_emails()
    
    all_classes, structured_classes = load_sorted_classes()
    if not all_classes:
        all_classes = ["æ¸¬è©¦ç­ç´š"]
        structured_classes = [{"grade": "å…¶ä»–", "name": "æ¸¬è©¦ç­ç´š"}]

    grades = sorted(list(set([c["grade"] for c in structured_classes])))

    def get_week_num(d):
        try:
            start = datetime.strptime(SYSTEM_CONFIG["semester_start"], "%Y-%m-%d").date()
            if isinstance(d, datetime): d = d.date()
            return max(0, ((d - start).days // 7) + 1)
        except: return 0

    now_tw = datetime.now(TW_TZ)
    today_tw = now_tw.date()

    st.sidebar.title("ğŸ« åŠŸèƒ½é¸å–®")
    app_mode = st.sidebar.radio("è«‹é¸æ“‡æ¨¡å¼", ["æˆ‘æ˜¯ç³¾å¯ŸéšŠ(è©•åˆ†)", "æˆ‘æ˜¯ç­ä¸Šè¡›ç”Ÿè‚¡é•·", "è¡›ç”Ÿçµ„å¾Œå°"])

    if st.sidebar.button("ğŸ’¥ å¼·åˆ¶é‡ç½®ç³»çµ±(æ¸…é™¤å¿«å–)"):
        st.cache_data.clear()
        st.success("è¨˜æ†¶é«”å·²æ¸…é™¤ï¼Œè«‹é‡æ–°æ“ä½œï¼"); st.rerun()

    if st.sidebar.checkbox("é¡¯ç¤ºç³»çµ±é€£ç·šç‹€æ…‹", value=True):
        if get_gspread_client(): st.sidebar.success("âœ… Google Sheets é€£ç·šæ­£å¸¸")
        else: st.sidebar.error("âŒ Sheets é€£ç·šå¤±æ•—")
        if "gcp_service_account" in st.secrets: st.sidebar.success("âœ… GCP æ†‘è­‰å·²è®€å–")
        else: st.sidebar.error("âš ï¸ æœªè¨­å®š GCP Service Account")

    # --- æ¨¡å¼1: ç³¾å¯Ÿè©•åˆ† ---
    if app_mode == "æˆ‘æ˜¯ç³¾å¯ŸéšŠ(è©•åˆ†)":
        st.title("ğŸ“ è¡›ç”Ÿç³¾å¯Ÿè©•åˆ†ç³»çµ±")
        if "team_logged_in" not in st.session_state: st.session_state["team_logged_in"] = False
        
        if not st.session_state["team_logged_in"]:
            with st.expander("ğŸ” èº«ä»½é©—è­‰", expanded=True):
                input_code = st.text_input("è«‹è¼¸å…¥éšŠä¼é€šè¡Œç¢¼", type="password")
                if st.button("ç™»å…¥"):
                    if input_code == st.secrets["system_config"]["team_password"]:
                        st.session_state["team_logged_in"] = True; st.rerun()
                    else: st.error("é€šè¡Œç¢¼éŒ¯èª¤")
        
        if st.session_state["team_logged_in"]:
            prefixes = sorted(list(set([p["id_prefix"] for p in INSPECTOR_LIST])))
            prefix_labels = [f"{p}é–‹é ­" for p in prefixes]
            if not prefix_labels: st.warning("æ‰¾ä¸åˆ°ç³¾å¯Ÿåå–®ï¼Œè«‹é€šçŸ¥è€å¸«åœ¨å¾Œå°å»ºç«‹åå–® (Sheet: inspectors)ã€‚")
            else:
                selected_prefix_label = st.radio("æ­¥é©Ÿ 1ï¼šé¸æ“‡é–‹é ­", prefix_labels, horizontal=True)
                selected_prefix = selected_prefix_label[0]
                filtered_inspectors = [p for p in INSPECTOR_LIST if p["id_prefix"] == selected_prefix]
                inspector_name = st.radio("æ­¥é©Ÿ 2ï¼šé»é¸èº«ä»½", [p["label"] for p in filtered_inspectors])
                current_inspector_data = next((p for p in INSPECTOR_LIST if p["label"] == inspector_name), None)
                allowed_roles = current_inspector_data.get("allowed_roles", ["å…§æƒæª¢æŸ¥"])
                
                allowed_roles = [r for r in allowed_roles if r != "æ™¨é–“æ‰“æƒ"]
                if not allowed_roles: allowed_roles = ["å…§æƒæª¢æŸ¥"] 
                assigned_classes = current_inspector_data.get("assigned_classes", [])
                
                st.markdown("---")
                col_date, col_role = st.columns(2)
                input_date = col_date.date_input("æª¢æŸ¥æ—¥æœŸ", today_tw)
                if len(allowed_roles) > 1: role = col_role.radio("è«‹é¸æ“‡æª¢æŸ¥é …ç›®", allowed_roles, horizontal=True)
                else: role = allowed_roles[0]; col_role.info(f"ğŸ“‹ æ‚¨çš„è² è²¬é …ç›®ï¼š**{role}**")
                
                week_num = get_week_num(input_date)
                st.caption(f"ğŸ“… ç¬¬ {week_num} é€±")
                main_df = load_main_data()

                if role == "åƒåœ¾/å›æ”¶æª¢æŸ¥":
                    st.info("ğŸ—‘ï¸ å…¨æ ¡åƒåœ¾æª¢æŸ¥ (æ¯æ—¥æ¯ç­ä¸Šé™æ‰£2åˆ†)")
                    trash_cat = st.radio("é•è¦é …ç›®", ["ä¸€èˆ¬åƒåœ¾", "ç´™é¡", "ç¶²è¢‹", "å…¶ä»–å›æ”¶"], horizontal=True)
                    with st.form("trash_form"):
                        t_data = [{"ç­ç´š": c, "ç„¡ç°½å": False, "ç„¡åˆ†é¡": False} for c in all_classes]
                        edited_t_df = st.data_editor(pd.DataFrame(t_data), hide_index=True, height=400, use_container_width=True)
                        if st.form_submit_button("é€å‡º"):
                            base = {"æ—¥æœŸ": input_date, "é€±æ¬¡": week_num, "æª¢æŸ¥äººå“¡": inspector_name, "ç™»éŒ„æ™‚é–“": now_tw.strftime("%Y-%m-%d %H:%M:%S"), "ä¿®æ­£": False}
                            cnt = 0
                            for _, row in edited_t_df.iterrows():
                                vios = []
                                if row["ç„¡ç°½å"]: vios.append("ç„¡ç°½å")
                                if row["ç„¡åˆ†é¡"]: vios.append("ç„¡åˆ†é¡")
                                if vios:
                                    save_entry({**base, "ç­ç´š": row["ç­ç´š"], "è©•åˆ†é …ç›®": role, "åƒåœ¾åŸå§‹åˆ†": len(vios), "å‚™è¨»": f"{trash_cat}-{'ã€'.join(vios)}", "é•è¦ç´°é …": trash_cat})
                                    cnt += 1
                            st.success(f"å·²æ’å…¥èƒŒæ™¯è™•ç†ï¼š {cnt} ç­" if cnt else "ç„¡é•è¦"); st.rerun()
                else:
                    st.markdown("### ğŸ«é¸æ“‡ç­ç´š")
                    if assigned_classes: selected_class = st.radio("è«‹é»é¸ç­ç´š", assigned_classes)
                    else:
                        g = st.radio("å¹´ç´š", grades, horizontal=True)
                        selected_class = st.radio("ç­ç´š", [c["name"] for c in structured_classes if c["grade"] == g], horizontal=True)
                    
                    if selected_class:
                        if check_duplicate_record(main_df, input_date, inspector_name, role, selected_class):
                                st.warning(f"âš ï¸ æ³¨æ„ï¼šæ‚¨ä»Šå¤©å·²ç¶“è©•éã€Œ{selected_class}ã€äº†ï¼")
                        st.info(f"ğŸ“ æ­£åœ¨è©•åˆ†ï¼š**{selected_class}**")
                        with st.form("scoring_form", clear_on_submit=True):
                            in_s = 0; out_s = 0; ph_c = 0; note = ""
                            if role == "å…§æƒæª¢æŸ¥":
                                if st.radio("çµæœ", ["âŒ é•è¦", "âœ¨ ä¹¾æ·¨"], horizontal=True) == "âŒ é•è¦":
                                    in_s = st.number_input("å…§æƒæ‰£åˆ† (ä¸Šé™2åˆ†)", 0); note = st.text_input("èªªæ˜", placeholder="é»‘æ¿æœªæ“¦"); ph_c = st.number_input("æ‰‹æ©Ÿäººæ•¸ (ç„¡ä¸Šé™)", 0)
                                else: note = "ã€å„ªè‰¯ã€‘"
                            elif role == "å¤–æƒæª¢æŸ¥":
                                if st.radio("çµæœ", ["âŒ é•è¦", "âœ¨ ä¹¾æ·¨"], horizontal=True) == "âŒ é•è¦":
                                    out_s = st.number_input("å¤–æƒæ‰£åˆ† (ä¸Šé™2åˆ†)", 0); note = st.text_input("èªªæ˜", placeholder="èµ°å»Šåƒåœ¾"); ph_c = st.number_input("æ‰‹æ©Ÿäººæ•¸ (ç„¡ä¸Šé™)", 0)
                                else: note = "ã€å„ªè‰¯ã€‘"

                            is_fix = st.checkbox("ğŸš© ä¿®æ­£å–®"); files = st.file_uploader("ç…§ç‰‡(è‡ªå‹•ä¸Šå‚³é›²ç«¯)", accept_multiple_files=True)
                            if st.form_submit_button("é€å‡º"):
                                save_entry(
                                    {"æ—¥æœŸ": input_date, "é€±æ¬¡": week_num, "æª¢æŸ¥äººå“¡": inspector_name, "ç™»éŒ„æ™‚é–“": now_tw.strftime("%Y-%m-%d %H:%M:%S"), "ä¿®æ­£": is_fix, "ç­ç´š": selected_class, "è©•åˆ†é …ç›®": role, "å…§æƒåŸå§‹åˆ†": in_s, "å¤–æƒåŸå§‹åˆ†": out_s, "æ‰‹æ©Ÿäººæ•¸": ph_c, "å‚™è¨»": note},
                                    uploaded_files=files
                                )
                                st.toast(f"âœ… å·²æ’å…¥å„²å­˜ä½‡åˆ—ï¼š{selected_class}"); st.rerun()

    # --- æ¨¡å¼2: è¡›ç”Ÿè‚¡é•· ---
    elif app_mode == "æˆ‘æ˜¯ç­ä¸Šè¡›ç”Ÿè‚¡é•·":
        st.title("ğŸ” ç­ç´šæŸ¥è©¢ & é•è¦ç”³è¨´")
        df = load_main_data()
        if not df.empty:
            st.write("è«‹ä¾ç…§æ­¥é©Ÿé¸æ“‡ï¼š")
            g = st.radio("æ­¥é©Ÿ 1ï¼šé¸æ“‡å¹´ç´š", grades, horizontal=True)
            class_options = [c["name"] for c in structured_classes if c["grade"] == g]
            cls = st.radio("æ­¥é©Ÿ 2ï¼šé¸æ“‡ç­ç´š", class_options, horizontal=True)
            st.divider()
            c_df = df[df["ç­ç´š"] == cls].sort_values("ç™»éŒ„æ™‚é–“", ascending=False)
            three_days_ago = date.today() - timedelta(days=3)
            
            if not c_df.empty:
                st.subheader(f"ğŸ“Š {cls}è¿‘æœŸç´€éŒ„")
                for idx, r in c_df.iterrows():
                    total_raw = r['å…§æƒåŸå§‹åˆ†']+r['å¤–æƒåŸå§‹åˆ†']+r['åƒåœ¾åŸå§‹åˆ†']+r['æ™¨é–“æ‰“æƒåŸå§‹åˆ†']
                    phone_msg = f" | ğŸ“±æ‰‹æ©Ÿ: {r['æ‰‹æ©Ÿäººæ•¸']}" if r['æ‰‹æ©Ÿäººæ•¸'] > 0 else ""
                    with st.expander(f"{r['æ—¥æœŸ']} - {r['è©•åˆ†é …ç›®']} (æ‰£åˆ†: {total_raw}){phone_msg}"):
                        st.write(f"ğŸ“ èªªæ˜: {r['å‚™è¨»']}"); st.caption(f"æª¢æŸ¥äººå“¡: {r['æª¢æŸ¥äººå“¡']}")
                        raw_photo_path = str(r.get("ç…§ç‰‡è·¯å¾‘", "")).strip()
                        if raw_photo_path and raw_photo_path.lower() != "nan":
                            path_list = [p.strip() for p in raw_photo_path.split(";") if p.strip()]
                            valid_photos = [p for p in path_list if p != "UPLOAD_FAILED" and (p.startswith("http") or os.path.exists(p))]
                            if valid_photos:
                                captions = [f"é•è¦ç…§ç‰‡ ({i+1})" for i in range(len(valid_photos))]
                                st.image(valid_photos, caption=captions, width=300)
                            elif "UPLOAD_FAILED" in path_list: st.warning("âš ï¸ ç…§ç‰‡ä¸Šå‚³å¤±æ•—")

                        if total_raw > 2 and r['æ™¨é–“æ‰“æƒåŸå§‹åˆ†'] == 0:
                            st.info("ğŸ’¡ç³»çµ±æç¤ºï¼šå–®é …æ¯æ—¥æ‰£åˆ†ä¸Šé™ç‚º 2 åˆ† (æ‰‹æ©Ÿã€æ™¨æƒé™¤å¤–)ï¼Œæœ€çµ‚æˆç¸¾å°‡ç”±å¾Œå°è‡ªå‹•è¨ˆç®—ä¸Šé™ã€‚")

                        record_date_obj = pd.to_datetime(r['æ—¥æœŸ']).date() if isinstance(r['æ—¥æœŸ'], str) else r['æ—¥æœŸ']
                        if record_date_obj >= three_days_ago and (total_raw > 0 or r['æ‰‹æ©Ÿäººæ•¸'] > 0):
                            st.markdown("---"); st.markdown("#### ğŸš¨ æˆ‘è¦ç”³è¨´")
                            form_key = f"appeal_form_{r['ç´€éŒ„ID']}_{idx}"
                            with st.form(form_key):
                                reason = st.text_area("ç”³è¨´ç†ç”±", height=80, placeholder="è©³ç´°èªªæ˜...")
                                proof_file = st.file_uploader("ä¸Šå‚³ä½è­‰ (å¿…å¡«)", type=["jpg", "png", "jpeg"], key=f"file_{idx}")
                                if st.form_submit_button("æäº¤ç”³è¨´"):
                                    if not reason or not proof_file: st.error("âŒ è«‹å¡«å¯«ç†ç”±ä¸¦ä¸Šå‚³ç…§ç‰‡")
                                    else:
                                        appeal_entry = {
                                            "ç”³è¨´æ—¥æœŸ": str(date.today()), "ç­ç´š": cls, "é•è¦æ—¥æœŸ": str(r["æ—¥æœŸ"]),
                                            "é•è¦é …ç›®": f"{r['è©•åˆ†é …ç›®']} ({r['å‚™è¨»']})", "åŸå§‹æ‰£åˆ†": str(total_raw),
                                            "ç”³è¨´ç†ç”±": reason, "è™•ç†ç‹€æ…‹": "å¾…è™•ç†",
                                            "ç™»éŒ„æ™‚é–“": datetime.now(TW_TZ).strftime("%Y-%m-%d %H:%M:%S"),
                                            "å°æ‡‰ç´€éŒ„ID": r['ç´€éŒ„ID']
                                        }
                                        if save_appeal(appeal_entry, proof_file): st.success("âœ… ç”³è¨´å·²æäº¤ï¼"); st.rerun()
                                        else: st.error("æäº¤å¤±æ•—")
                        elif total_raw > 0: st.caption("â³ å·²è¶…é 3 å¤©ç”³è¨´æœŸé™ã€‚")
            else: st.info("ç„¡ç´€éŒ„")

    # --- æ¨¡å¼3: å¾Œå° ---
    elif app_mode == "è¡›ç”Ÿçµ„å¾Œå°":
        st.title("âš™ï¸ ç®¡ç†å¾Œå°")
        q_size = get_queue_pending_count()
        if q_size > 0:
            st.warning(f"ğŸš€ èƒŒæ™¯ç³»çµ±å¿™ç¢Œä¸­ï¼šå°šæœ‰ {q_size} ç­†è³‡æ–™æ’éšŠå¯«å…¥ï¼ˆSQLite Queueï¼‰...")
        else:
            st.success("âœ… ç³»çµ±å¾…æ©Ÿä¸­ï¼šæ‰€æœ‰è³‡æ–™å·²åŒæ­¥å®Œæˆ")

        pwd = st.text_input("ç®¡ç†å¯†ç¢¼", type="password")
        if pwd == st.secrets["system_config"]["admin_password"]:
            tab1, tab2, tab3, tab4, tab5, tab6, tab7 = st.tabs([
                "ğŸ“Š æˆç¸¾ç¸½è¡¨", "ğŸ“ è©³ç´°æ˜ç´°", "ğŸ“§ å¯„é€é€šçŸ¥", 
                "ğŸ“£ ç”³è¨´å¯©æ ¸", "âš™ï¸ ç³»çµ±è¨­å®š", "ğŸ“„ åå–®ç®¡ç†", "ğŸ§¹ æ™¨æƒç®¡ç†"
            ])
            
            with tab1: # æˆç¸¾ç¸½è¡¨
                st.subheader("æˆç¸¾æ’è¡Œæ¦œèˆ‡ç¸½è¡¨")
                df = load_main_data()
                all_classes_df = pd.DataFrame(all_classes, columns=["ç­ç´š"])
                if not df.empty:
                    valid_weeks = sorted(df[df["é€±æ¬¡"]>0]["é€±æ¬¡"].unique())
                    # [Fix]: Added key='week_select_summary' to avoid ID collision
                    selected_weeks = st.multiselect("é¸æ“‡é€±æ¬¡", valid_weeks, default=valid_weeks[-1:] if valid_weeks else [], key='week_select_summary')
                    if selected_weeks:
                        wdf = df[df["é€±æ¬¡"].isin(selected_weeks)].copy()
                        daily_agg = wdf.groupby(["æ—¥æœŸ", "ç­ç´š"]).agg({
                            "å…§æƒåŸå§‹åˆ†": "sum", "å¤–æƒåŸå§‹åˆ†": "sum", "åƒåœ¾åŸå§‹åˆ†": "sum",
                            "æ™¨é–“æ‰“æƒåŸå§‹åˆ†": "sum", "æ‰‹æ©Ÿäººæ•¸": "sum"
                        }).reset_index()
                        daily_agg["å…§æƒçµç®—"] = daily_agg["å…§æƒåŸå§‹åˆ†"].apply(lambda x: min(x, 2))
                        daily_agg["å¤–æƒçµç®—"] = daily_agg["å¤–æƒåŸå§‹åˆ†"].apply(lambda x: min(x, 2))
                        daily_agg["åƒåœ¾çµç®—"] = daily_agg["åƒåœ¾åŸå§‹åˆ†"].apply(lambda x: min(x, 2))
                        daily_agg["æ¯æ—¥ç¸½æ‰£åˆ†"] = (daily_agg["å…§æƒçµç®—"] + daily_agg["å¤–æƒçµç®—"] + 
                                                 daily_agg["åƒåœ¾çµç®—"] + daily_agg["æ™¨é–“æ‰“æƒåŸå§‹åˆ†"] + daily_agg["æ‰‹æ©Ÿäººæ•¸"])
                        violation_report = daily_agg.groupby("ç­ç´š").agg({
                            "å…§æƒçµç®—": "sum", "å¤–æƒçµç®—": "sum", "åƒåœ¾çµç®—": "sum",
                            "æ™¨é–“æ‰“æƒåŸå§‹åˆ†": "sum", "æ‰‹æ©Ÿäººæ•¸": "sum", "æ¯æ—¥ç¸½æ‰£åˆ†": "sum"
                        }).reset_index()
                        violation_report.columns = ["ç­ç´š", "å…§æƒæ‰£åˆ†", "å¤–æƒæ‰£åˆ†", "åƒåœ¾æ‰£åˆ†", "æ™¨æƒæ‰£åˆ†", "æ‰‹æ©Ÿæ‰£åˆ†", "ç¸½æ‰£åˆ†"]
                        final_report = pd.merge(all_classes_df, violation_report, on="ç­ç´š", how="left").fillna(0)
                        final_report["ç¸½æˆç¸¾"] = 90 - final_report["ç¸½æ‰£åˆ†"]
                        final_report = final_report.sort_values("ç¸½æˆç¸¾", ascending=False)
                        st.dataframe(final_report, column_config={
                            "ç¸½æˆç¸¾": st.column_config.ProgressColumn("ç¸½æˆç¸¾", format="%d", min_value=60, max_value=90),
                            "ç¸½æ‰£åˆ†": st.column_config.NumberColumn("ç¸½æ‰£åˆ†", format="%d åˆ†")
                        }, use_container_width=True)
                        csv = final_report.to_csv(index=False).encode('utf-8-sig')
                        st.download_button("ğŸ“¥ ä¸‹è¼‰ (CSV)", csv, f"report_weeks_{selected_weeks}.csv")
                    else: st.info("è«‹é¸æ“‡é€±æ¬¡")
                else: st.warning("ç„¡è³‡æ–™")

            with tab2: # è©³ç´°æ˜ç´°
                st.subheader("ğŸ“ é•è¦è©³ç´°æµæ°´å¸³")
                df = load_main_data()
                if not df.empty:
                    valid_weeks = sorted(df[df["é€±æ¬¡"]>0]["é€±æ¬¡"].unique())
                    # [Fix]: Added key='week_select_detail' to avoid ID collision
                    s_weeks = st.multiselect("é¸æ“‡é€±æ¬¡", valid_weeks, default=valid_weeks[-1:] if valid_weeks else [], key='week_select_detail')
                    if s_weeks:
                        detail_df = df[df["é€±æ¬¡"].isin(s_weeks)].copy()
                        detail_df["è©²ç­†æ‰£åˆ†"] = detail_df["å…§æƒåŸå§‹åˆ†"] + detail_df["å¤–æƒåŸå§‹åˆ†"] + detail_df["åƒåœ¾åŸå§‹åˆ†"] + detail_df["æ™¨é–“æ‰“æƒåŸå§‹åˆ†"] + detail_df["æ‰‹æ©Ÿäººæ•¸"]
                        detail_df = detail_df[detail_df["è©²ç­†æ‰£åˆ†"] > 0]
                        display_cols = ["æ—¥æœŸ", "ç­ç´š", "è©•åˆ†é …ç›®", "è©²ç­†æ‰£åˆ†", "å‚™è¨»", "æª¢æŸ¥äººå“¡", "é•è¦ç´°é …", "ç´€éŒ„ID"]
                        detail_df = detail_df[display_cols].sort_values(["æ—¥æœŸ", "ç­ç´š"])
                        st.dataframe(detail_df, use_container_width=True)
                        csv_detail = detail_df.to_csv(index=False).encode('utf-8-sig')
                        st.download_button("ğŸ“¥ ä¸‹è¼‰ (CSV)", csv_detail, f"detail_log_{s_weeks}.csv")
                    else: st.info("è«‹é¸æ“‡é€±æ¬¡")
                else: st.info("ç„¡è³‡æ–™")

            with tab3: # å¯„é€é€šçŸ¥ (å·²å„ªåŒ–)
                st.subheader("ğŸ“§ æ¯æ—¥é•è¦é€šçŸ¥")
                target_date = st.date_input("é¸æ“‡æ—¥æœŸ", today_tw)
                if "mail_preview" not in st.session_state: st.session_state.mail_preview = None
                if st.button("ğŸ” æœå°‹ç•¶æ—¥é•è¦"):
                    df = load_main_data()
                    try:
                        df["æ—¥æœŸObj"] = pd.to_datetime(df["æ—¥æœŸ"], errors='coerce').dt.date
                        day_df = df[df["æ—¥æœŸObj"] == target_date]
                    except: day_df = pd.DataFrame()
                    if not day_df.empty:
                        stats = day_df.groupby("ç­ç´š")[["å…§æƒåŸå§‹åˆ†", "å¤–æƒåŸå§‹åˆ†", "åƒåœ¾åŸå§‹åˆ†", "æ™¨é–“æ‰“æƒåŸå§‹åˆ†", "æ‰‹æ©Ÿäººæ•¸"]].sum().reset_index()
                        stats["å…§æƒ"] = stats["å…§æƒåŸå§‹åˆ†"].clip(upper=2)
                        stats["å¤–æƒ"] = stats["å¤–æƒåŸå§‹åˆ†"].clip(upper=2)
                        stats["åƒåœ¾"] = stats["åƒåœ¾åŸå§‹åˆ†"].clip(upper=2)
                        stats["ç•¶æ—¥ç¸½æ‰£åˆ†"] = stats["å…§æƒ"] + stats["å¤–æƒ"] + stats["åƒåœ¾"] + stats["æ™¨é–“æ‰“æƒåŸå§‹åˆ†"] + stats["æ‰‹æ©Ÿäººæ•¸"]
                        violation_classes = stats[stats["ç•¶æ—¥ç¸½æ‰£åˆ†"] > 0]
                        if not violation_classes.empty:
                            preview_data = []
                            for _, row in violation_classes.iterrows():
                                cls_name = row["ç­ç´š"]
                                t_info = TEACHER_MAILS.get(cls_name, {})
                                t_name = t_info.get('name', "âŒ ç¼ºåå–®")
                                t_email = t_info.get('email', "âŒ ç„¡æ³•å¯„é€")
                                status = "æº–å‚™å¯„é€" if "@" in t_email else "ç•°å¸¸"
                                preview_data.append({"ç­ç´š": cls_name, "ç•¶æ—¥ç¸½æ‰£åˆ†": row["ç•¶æ—¥ç¸½æ‰£åˆ†"], "å°å¸«å§“å": t_name, "æ”¶ä»¶ä¿¡ç®±": t_email, "ç‹€æ…‹": status})
                            st.session_state.mail_preview = pd.DataFrame(preview_data)
                            st.success(f"æ‰¾åˆ° {len(violation_classes)} ç­†é•è¦ç­ç´š")
                        else: st.session_state.mail_preview = None; st.info("ä»Šæ—¥ç„¡é•è¦")
                    else: st.session_state.mail_preview = None; st.info("ä»Šæ—¥ç„¡è³‡æ–™")

                if st.session_state.mail_preview is not None:
                    st.write("### ğŸ“¨ å¯„é€é è¦½æ¸…å–®"); st.dataframe(st.session_state.mail_preview)
                    if st.button("ğŸš€ ç¢ºèªå¤§é‡å¯„å‡º"):
                        mail_queue_list = []
                        for _, row in st.session_state.mail_preview.iterrows():
                            if row["ç‹€æ…‹"] == "æº–å‚™å¯„é€":
                                subject = f"è¡›ç”Ÿè©•åˆ†é€šçŸ¥ ({target_date}) - {row['ç­ç´š']}"
                                content = f"{row['å°å¸«å§“å']} è€å¸«æ‚¨å¥½ï¼š\n\nè²´ç­ä»Šæ—¥({target_date}) è¡›ç”Ÿè©•åˆ†ç¸½æ‰£åˆ†ç‚ºï¼š{row['ç•¶æ—¥ç¸½æ‰£åˆ†']} åˆ†ã€‚\nè«‹å”åŠ©ç£å°ï¼Œè¬è¬ã€‚\n\nè¡›ç”Ÿçµ„æ•¬ä¸Š"
                                mail_queue_list.append({'email': row["æ”¶ä»¶ä¿¡ç®±"], 'subject': subject, 'body': content})
                        
                        if mail_queue_list:
                            with st.spinner("ğŸ“§ æ­£åœ¨å»ºç«‹ SMTP é€£ç·šä¸¦æ‰¹æ¬¡å¯„é€..."):
                                count, msg = send_bulk_emails(mail_queue_list)
                                if count > 0: st.success(f"âœ… æˆåŠŸå¯„å‡º {count} å°ä¿¡ä»¶ï¼ ({msg})")
                                else: st.error(f"âŒ å¯„é€å¤±æ•—: {msg}")
                            st.session_state.mail_preview = None
                        else: st.warning("æ²’æœ‰å¯å¯„é€çš„å°è±¡")

            with tab4: # ç”³è¨´å¯©æ ¸
                st.subheader("ğŸ“£ ç”³è¨´æ¡ˆä»¶å¯©æ ¸")
                appeals_df = load_appeals()
                pending = appeals_df[appeals_df["è™•ç†ç‹€æ…‹"] == "å¾…è™•ç†"]
                if not pending.empty:
                    st.info(f"å¾…å¯©æ ¸: {len(pending)} ä»¶")
                    for idx, row in pending.iterrows():
                        with st.container(border=True):
                            c1, c2 = st.columns([2, 1])
                            with c1:
                                st.markdown(f"**{row['ç­ç´š']}** | {row['é•è¦é …ç›®']} | æ‰£ {row['åŸå§‹æ‰£åˆ†']} åˆ†")
                                st.markdown(f"ç†ç”±ï¼š{row['ç”³è¨´ç†ç”±']}")
                            with c2:
                                url = row.get("ä½è­‰ç…§ç‰‡", "")
                                if url and url != "UPLOAD_FAILED": st.image(url, width=150)
                            b1, b2 = st.columns(2)
                            if b1.button("âœ… æ ¸å¯", key=f"ok_{idx}"):
                                succ, msg = update_appeal_status(idx, "å·²æ ¸å¯", row["å°æ‡‰ç´€éŒ„ID"])
                                if succ: st.success("å·²æ ¸å¯"); time.sleep(1); st.rerun()
                            if b2.button("ğŸš« é§å›", key=f"ng_{idx}"):
                                succ, msg = update_appeal_status(idx, "å·²é§å›", row["å°æ‡‰ç´€éŒ„ID"])
                                if succ: st.warning("å·²é§å›"); time.sleep(1); st.rerun()
                else: st.success("ç„¡å¾…å¯©æ ¸æ¡ˆä»¶")
                with st.expander("æ­·å²æ¡ˆä»¶"): st.dataframe(appeals_df[appeals_df["è™•ç†ç‹€æ…‹"] != "å¾…è™•ç†"])

            with tab5: # ç³»çµ±è¨­å®š (è³‡æ–™åˆªé™¤å·²ä¿®æ­£)
                st.subheader("âš™ï¸ ç³»çµ±è¨­å®š")
                curr = SYSTEM_CONFIG.get("semester_start", "2025-08-25")
                nd = st.date_input("é–‹å­¸æ—¥", datetime.strptime(curr, "%Y-%m-%d").date())
                if st.button("æ›´æ–°é–‹å­¸æ—¥"): save_setting("semester_start", str(nd)); st.success("å·²æ›´æ–°")
                st.divider()
                st.markdown("### ğŸ—‘ï¸ è³‡æ–™ç¶­è­· (å®‰å…¨åˆªé™¤ç‰ˆ)")
                df = load_main_data()
                if not df.empty:
                    del_mode = st.radio("åˆªé™¤æ¨¡å¼", ["å–®ç­†åˆªé™¤", "æ—¥æœŸå€é–“åˆªé™¤"])
                    if del_mode == "å–®ç­†åˆªé™¤":
                        df_display = df.sort_values("ç™»éŒ„æ™‚é–“", ascending=False).head(50)
                        opts = {r['ç´€éŒ„ID']: f"{r['æ—¥æœŸ']} | {r['ç­ç´š']} | {r['è©•åˆ†é …ç›®']} (ID:{r['ç´€éŒ„ID']})" for _, r in df_display.iterrows()}
                        # [Fix]: Added key='del_multiselect' to avoid ID collision
                        sel_ids = st.multiselect("é¸æ“‡è¦åˆªé™¤çš„ç´€éŒ„", list(opts.keys()), format_func=lambda x: opts[x], key='del_multiselect')
                        if st.button("ğŸ—‘ï¸ ç¢ºèªåˆªé™¤"):
                            if delete_rows_by_ids(sel_ids): st.success("åˆªé™¤æˆåŠŸ"); st.rerun()
                    elif del_mode == "æ—¥æœŸå€é–“åˆªé™¤":
                        c1, c2 = st.columns(2)
                        d_start = c1.date_input("é–‹å§‹"); d_end = c2.date_input("çµæŸ")
                        if st.button("âš ï¸ ç¢ºèªåˆªé™¤å€é–“è³‡æ–™"):
                            df["d_tmp"] = pd.to_datetime(df["æ—¥æœŸ"], errors='coerce').dt.date
                            target_ids = df[(df["d_tmp"] >= d_start) & (df["d_tmp"] <= d_end)]["ç´€éŒ„ID"].tolist()
                            if target_ids:
                                if delete_rows_by_ids(target_ids): st.success(f"å·²åˆªé™¤ {len(target_ids)} ç­†"); st.rerun()
                            else: st.warning("ç„¡è³‡æ–™")
                else: st.info("ç„¡è³‡æ–™")

            with tab6:
                st.info("è«‹è‡³ Google Sheets ä¿®æ”¹åå–®")
                if st.button("ğŸ”„ é‡æ–°è®€å–å¿«å–"): st.cache_data.clear(); st.success("OK")
                st.markdown(f"[é–‹å•Ÿè©¦ç®—è¡¨]({SHEET_URL})")

            with tab7: # æ™¨æƒç®¡ç†
                st.subheader("ğŸ§¹ æ™¨æƒè©•åˆ†")
                m_date = st.date_input("æ—¥æœŸ", today_tw, key="m_d")
                m_week = get_week_num(m_date)
                duty_list, status = get_daily_duty(m_date)
                if status == "success":
                    st.write(f"æ‡‰åˆ°: {len(duty_list)} äºº")
                    with st.form("m_form"):
                        edited = st.data_editor(pd.DataFrame(duty_list), hide_index=True, use_container_width=True)
                        score = st.number_input("æ‰£åˆ†", min_value=1, value=1)
                        if st.form_submit_button("é€å‡º"):
                            base = {"æ—¥æœŸ": m_date, "é€±æ¬¡": m_week, "æª¢æŸ¥äººå“¡": "è¡›ç”Ÿçµ„", "ç™»éŒ„æ™‚é–“": now_tw.strftime("%Y-%m-%d %H:%M:%S"), "ä¿®æ­£": False}
                            cnt = 0
                            for _, r in edited[edited["å·²å®Œæˆæ‰“æƒ"] == False].iterrows():
                                tid = clean_id(r["å­¸è™Ÿ"])
                                cls = ROSTER_DICT.get(tid, f"æŸ¥ç„¡({tid})")
                                save_entry({**base, "ç­ç´š": cls, "è©•åˆ†é …ç›®": "æ™¨é–“æ‰“æƒ", "æ™¨é–“æ‰“æƒåŸå§‹åˆ†": score, "å‚™è¨»": f"æœªåˆ°-å­¸è™Ÿ:{tid}", "æ™¨æƒæœªåˆ°è€…": tid})
                                cnt += 1
                            st.success(f"å·²æ’å…¥èƒŒæ™¯ï¼š{cnt} äºº"); st.rerun()
                else: st.warning(f"ç„¡è¼ªå€¼è³‡æ–™ ({status})")

        else: st.error("å¯†ç¢¼éŒ¯èª¤")

except Exception as e:
    st.error("âŒ ç³»çµ±éŒ¯èª¤:"); st.error(str(e)); st.code(traceback.format_exc())










